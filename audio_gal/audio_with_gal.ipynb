{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepgram import Deepgram\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import mimetypes\n",
    "import guardrails as gd\n",
    "import openai\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env.local\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables for API Keys (see .env.example)\n",
    "ENV_FILE = \"../.env.local\"\n",
    "if os.path.exists(ENV_FILE):\n",
    "    load_dotenv(ENV_FILE, override=True)\n",
    "    print(\"Loaded .env.local\")\n",
    "else:\n",
    "    print(\"No .env.local found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize (i.e. Transcribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT_INPUT_FILE = \"earnings.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe with Deepgram if needed\n",
    "if not TRANSCRIPT_INPUT_FILE.endswith(\".json\"):\n",
    "    OUTPUT_FILE = TRANSCRIPT_INPUT_FILE.replace(\".mp3\", \".json\")\n",
    "    DEEPGRAM_API_KEY = os.environ.get(\"DEEPGRAM_API_KEY\")\n",
    "    MIMETYPE, _ = mimetypes.guess_type(TRANSCRIPT_INPUT_FILE)\n",
    "    audio = open(TRANSCRIPT_INPUT_FILE, 'rb')\n",
    "    source = {\n",
    "      'buffer': audio,\n",
    "      'mimetype': MIMETYPE\n",
    "    }\n",
    "    deepgram = Deepgram(DEEPGRAM_API_KEY)\n",
    "    transcript = await asyncio.create_task(\n",
    "        deepgram.transcription.prerecorded(\n",
    "        source,\n",
    "        {\n",
    "            'smart_format': True,\n",
    "            'model': 'nova',\n",
    "        }\n",
    "        )\n",
    "    )\n",
    "    with open(OUTPUT_FILE, 'w') as outfile:\n",
    "        json.dump(transcript, outfile)\n",
    "    transcript_text = transcript[\"results\"][\"channels\"][0][\"alternatives\"][0][\"transcript\"]\n",
    "else:\n",
    "    with open(TRANSCRIPT_INPUT_FILE, \"r\") as f:\n",
    "        transcript = json.load(f)\n",
    "        transcript_text = transcript[\"results\"][\"channels\"][0][\"alternatives\"][0][\"transcript\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard = gd.Guard.from_rail(\"audio.rail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_text = transcript[\"results\"][\"channels\"][0][\"alternatives\"][0][\"transcript\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: $56,200,000,000\n",
      "Excerpts: ['This quarter, revenue was 56,200,000,000 dollars, up 8% 10% in constant currency.']\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the revenue?\"\n",
    "raw_llm_output, validated_output = guard(\n",
    "    openai.ChatCompletion.create,\n",
    "    prompt_params={\"transcript\": transcript_text, \"user_question\": question},\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "if validated_output is None or  \"transcript_qa\" not in validated_output:\n",
    "    print(f\"Error: {validated_output}\")\n",
    "else:\n",
    "    answer = validated_output[\"transcript_qa\"][\"answer\"]\n",
    "    excerpts = [e[\"excerpt\"] for e in validated_output[\"transcript_qa\"][\"transcript_excerpts\"]]\n",
    "\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Excerpts: {excerpts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.replace(\" \", \"\") \n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def localize_chunk(transcript, chunk_text):\n",
    "    \"\"\"\n",
    "        Localizes a str within a list\n",
    "\n",
    "        transcript: a list of {'word': str, 'start': float, 'end': float}\n",
    "        \n",
    "        chunk_text: string\n",
    "            chunk_text exists as a string of words in the transcript list. each word in \n",
    "            chunk_text is a word in transcript[i]['word']\n",
    "\n",
    "        return the start and end indices within the transcript list\n",
    "    \"\"\"\n",
    "    chunk_words = chunk_text.split(\" \")\n",
    "    for i, word_info in enumerate(transcript):\n",
    "        if clean_string(word_info['punctuated_word']) == clean_string(chunk_words[0]): # found start of string\n",
    "            found = True\n",
    "            for j in range(1, len(chunk_words)): # see if it continues\n",
    "                if clean_string(transcript[i+j]['punctuated_word']) != clean_string(chunk_words[j]):\n",
    "                    found = False\n",
    "                    break\n",
    "            if found:\n",
    "                return i, i + len(chunk_words) - 1\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "There can be a range of \"UIs\" built to show the results of the GAL process, but for this notebook we will just\n",
    "print out the results in a formatted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: $56,200,000,000\n",
      "\n",
      "I generated this answer based on the following excerpts:\n",
      "\t'This quarter, revenue was 56,200,000,000 dollars, up 8% 10% in constant currency.' found at time 1483.8656s to 1489.5656s in earnings.mp3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_str = f\"\"\"\n",
    "Answer: {answer}\n",
    "\n",
    "I generated this answer based on the following excerpts:\n",
    "\"\"\"\n",
    "for excerpt in excerpts:\n",
    "    start_index, end_index = localize_chunk(transcript[\"results\"][\"channels\"][0][\"alternatives\"][0][\"words\"], excerpt)\n",
    "    start_time, end_time = transcript[\"results\"][\"channels\"][0][\"alternatives\"][0][\"words\"][start_index][\"start\"], transcript[\"results\"][\"channels\"][0][\"alternatives\"][0][\"words\"][end_index][\"end\"]\n",
    "    output_str += f\"\\t'{excerpt}' found at time {start_time}s to {end_time}s in {TRANSCRIPT_INPUT_FILE}\\n\"\n",
    "\n",
    "print(output_str)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
